<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
	<channel>
		<title>Probabilistic-Numerics.org</title>
		<description>A community website collecting research on algorithms that assign probability distributions to the unknown result of deterministic computations.</description>		
		<link>http://www.probabilistic-numerics.org/test</link>
		<atom:link href="http://www.probabilistic-numerics.org/test/feed.xml" rel="self" type="application/rss+xml" />
		
			<item>
				<title>Tübingen Manifesto: Probabilistic Numerics and Probabilistic Programming</title>
				<description>&lt;p&gt;We in Probabilistic Numerics face many unanswered questions in growing the field.
Our &lt;a href=&quot;/2014/08/22/Roundtable-2014-in-Tuebingen&quot;&gt;roundtable in Tübingen&lt;/a&gt; aimed to bring together our new community to begin to address some of these questions. 
This is another of a sequence of posts that attempt to collate some of what we spoke about, and to, hopefully, provoke further discussion.&lt;/p&gt;

&lt;p&gt;We were very fortunate to benefit from the coincidental presence of &lt;a href=&quot;http://stanford.edu/~ngoodman/&quot;&gt;Noah Goodman&lt;/a&gt; in Tübingen, who generously spent an afternoon at the roundtable talking with us. 
Noah, of course, is a founding and deeply committed member of the &lt;a href=&quot;http://probabilistic-programming.org/wiki/Home&quot;&gt;Probabilistic Programming&lt;/a&gt; community.
Noah had many fascinating reflections on developments within Probabilistic Programming (ProbProg), and how they might connect with Probabilistic Numerics (ProbNum). &lt;/p&gt;

&lt;p&gt;ProbProg seems to be largely about allowing the design of complex generative models, and then ensuring that uncertainty is properly propagated in producing posteriors using the model.
This is certainly not the same as the propagation required to manage uncertainty introduced through the use of finite-precision or approximate numerical procedures, but there are some commonalities. 
Below are a number of items drawing out some of the links between the fields.&lt;/p&gt;

&lt;p&gt;ProbNum offers the attractive potential of performing decision-theoretic management of systems of probabilistic numerical algorithms. 
That is, ProbNum could be used to select which part of a numerical pipeline to refine, that is, to decide when to stop a numerical algorithm achieving accuracy you don’t need.
Noah was interested in this process, which he likened to &lt;a href=&quot;http://mlg.eng.cam.ac.uk/duvenaud/talks/tea_talk_metareasoning/index.html&quot;&gt;&lt;em&gt;meta-reasoning,&lt;/em&gt;&lt;/a&gt; and recommended making the connection explicit. &lt;/p&gt;

&lt;p&gt;Noah also posed the excellent question of how much computation it was worth spending to perform this meta-reasoning. 
Of course, this is a question we couldn’t readily answer.
Would a greedy selection of the numerical algorithm to spend the next unit of computation on be sufficient, or would more sophisticated strategies be required?
At this point, Noah quoted &lt;a href=&quot;http://www.cs.berkeley.edu/~russell/&quot;&gt;Stuart Russell&lt;/a&gt; in recommending that, as a rule, “you should only do as much meta-reasoning as regular reasoning”. This seems sensible enough to me!&lt;/p&gt;

&lt;p&gt;Noah also mentioned links between ProbNum’s approach of returning numerical results of flexible degrees of accuracy to the notion of &lt;a href=&quot;http://en.wikipedia.org/wiki/Lazy_evaluation&quot;&gt;&lt;em&gt;lazy evaluation&lt;/em&gt;&lt;/a&gt; common in functional languages like Haskell.
In either case, only as much computation is performed as is absolutely required.
For lazy evaluation, what is required can be determined exactly, whereas the ProbNum approach would treat this as a question to be answered with decision theory. &lt;/p&gt;

&lt;p&gt;Another fundamental concept in languages that we discussed was that of &lt;a href=&quot;http://en.wikipedia.org/wiki/Function_overloading&quot;&gt;&lt;em&gt;overloading&lt;/em&gt;&lt;/a&gt;. 
Treating, for example, a probability distribution over integers as a type that generalises the type &lt;code&gt;int&lt;/code&gt;, ProbNum might well benefit from being implemented using overloading.
That is, functions could be overloaded to permit the optional input and output of variances in addition to the usual input and output estimates.&lt;/p&gt;

&lt;p&gt;In probabilistic programming, uncertainty is represented largely by bags of samples. 
It would certainly be interesting to use Bayesian Quadrature downstream of a probabilistic program to try to make better use of those samples.
In such a setting, Bayesian quadrature might even benefit from access to the structure of the probabilistic model, available in the probabilistic program source code.
This structure might inform the mean and covariance functions chosen for the Gaussian process model used within Bayesian quadrature, for example.
A similar approach is at the heart of &lt;a href=&quot;http://www.autodiff.org/&quot;&gt;autodiff&lt;/a&gt;, which analyses the code for a function so as to allow for the computation of its derivatives.
Why shouldn’t we do the same thing in computing integrals?&lt;/p&gt;

</description>
				<pubDate>Thu, 28 Aug 2014 20:00:00 +0200</pubDate>
				<link>http://www.probabilistic-numerics.org/test/2014/08/28/Roundtable-ProbNum-ProbProg</link>
				<guid isPermaLink="true">http://www.probabilistic-numerics.org/test/2014/08/28/Roundtable-ProbNum-ProbProg</guid>
			</item>
		
			<item>
				<title>Tübingen Manifesto: Uncertainty</title>
				<description>&lt;p&gt;We in Probabilistic Numerics face many unanswered questions in growing the field.
Our &lt;a href=&quot;/2014/08/22/Roundtable-2014-in-Tuebingen&quot;&gt;roundtable in Tübingen&lt;/a&gt; aimed to bring together our new community to begin to address some of these questions. 
This is the first of a sequence of posts that attempt to collate some of what we spoke about, and to, hopefully, provoke further discussion.&lt;/p&gt;

&lt;p&gt;Our first major question was: &lt;em&gt;what is a well-defined notion of “uncertainty” for a probabilistic numerical method?&lt;/em&gt; 
Consider &lt;script type=&quot;math/tex&quot;&gt;\psi = \int_{0}^{1} \exp\bigl((\sin 3 x)^2 + x^2\bigr)\mathrm{d}x&lt;/script&gt;. 
In a sense, we know &lt;script type=&quot;math/tex&quot;&gt;\psi&lt;/script&gt;: I was able to write it down using a small number of mathematical symbols.
However, of course, to find &lt;script type=&quot;math/tex&quot;&gt;\psi&lt;/script&gt; to three significant figures, I, for one, would have to use a numerical algorithm (please let &lt;a href=&quot;&amp;#109;&amp;#097;&amp;#105;&amp;#108;&amp;#116;&amp;#111;:&amp;#109;&amp;#111;&amp;#115;&amp;#098;&amp;#064;&amp;#114;&amp;#111;&amp;#098;&amp;#111;&amp;#116;&amp;#115;&amp;#046;&amp;#111;&amp;#120;&amp;#046;&amp;#097;&amp;#099;&amp;#046;&amp;#117;&amp;#107;&quot;&gt;me&lt;/a&gt; know if you do actually have a closed form expression for &lt;script type=&quot;math/tex&quot;&gt;\psi&lt;/script&gt;!). 
Given the finite precision of any numerical algorithm, can we really still be said to know &lt;script type=&quot;math/tex&quot;&gt;\psi&lt;/script&gt;?
If not, how should we think about the uncertainty in &lt;script type=&quot;math/tex&quot;&gt;\psi&lt;/script&gt;?&lt;/p&gt;

&lt;p&gt;On this, I think the roundtable arrived at a helpful consensus.
We came to the conclusion that uncertainty for probabilistic numerical algorithms was &lt;em&gt;exactly the same quantity&lt;/em&gt; that we are used to in statistics.
That is, a probabilistic numerical algorithm is doing exactly what we do in statistics: collecting data and estimating.
Specifically, a numerical integration algorithm, tasked with finding &lt;script type=&quot;math/tex&quot;&gt;\psi&lt;/script&gt;, would collect evaluations of the integrand, and use them to estimate the integral.
For a probabilistic numerical integration algorithm, these evaluations will be used to inform a probabilistic model for the integrand, typically a Gaussian process, which can then be used to determine a posterior probability density for the integral.
As such, we can use exactly the notion of uncertainty we’re used to from any other form of statistical or probabilistic reasoning.
As with other probabilistic calculations, we could, if we desired, reframe the whole of probabilistic numerics as compression, using the language of coding theory. 
Whichever language we use, uncertainty in probabilistic numerics is clearly building on solid, existing, foundations.&lt;/p&gt;

&lt;p&gt;Of course, there is a caveat: the uncertainty returned by a probabilistic numerics algorithm is conditional on the prior information upon which it is constructed. 
Whether the returned uncertainty makes any sense will depend critically on the quality of the prior information included.
For example, in ODE solving, standard numerical algorithms typically ignore the uncertainty in past evaluations: final distributions will thus typically be unreasonably confident.
The output of numerical integration algorithms will likewise be 
reliant on the assumptions built into the inference for the probabilistic model for the integrand.
In constructing probabilistic numeric algorithms, we must be careful to ensure that our prior assumptions reflect, as best as possible, our true state of knowledge.&lt;/p&gt;

&lt;p&gt;More notes from the workshop to follow!&lt;/p&gt;
</description>
				<pubDate>Wed, 27 Aug 2014 00:00:00 +0200</pubDate>
				<link>http://www.probabilistic-numerics.org/test/2014/08/27/Roundtable-Uncertainty</link>
				<guid isPermaLink="true">http://www.probabilistic-numerics.org/test/2014/08/27/Roundtable-Uncertainty</guid>
			</item>
		
			<item>
				<title>Roundtable in Tübingen</title>
				<description>&lt;p&gt;&lt;strong&gt;Researchers interested in probabilistic numerical methods gathered for a
two-day discussion forum on August 21-22 2014 at the Max Planck Institute for
Intelligent Systems in Tübingen.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/roof.jpeg&quot; width=&quot;100%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The roundtable was organised by Philipp Hennig (MPI Tübingen) and Michael
Osborne (Oxford). Mark Girolami (UCL / Warwick) presented an invited talk.&lt;/p&gt;

&lt;p&gt;The roundtable took place from the morning of 21 August to the early afternoon
of 22 August. Hosted by the Max Planck Institute for Intelligent Systems in
Tübingen, Germany, it provided an informal setting for everyone interested in
the development of probabilistic numerical methods. The roundtable was neither
a workshop nor a conference. There are no proceedings, and attendees did not
have to submit a paper to attend. Apart from a small number of talks, the
schedule focused strongly on small-group discussions on specific aspects. Some
of the questions discussed in 2014 included&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;What is a well-defined notion of “uncertainty” for a probabilistic numerical
method? What are the limits of error estimation?&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;What are good data-structures for the communication between numerical methods
in a pipeline? How can numerical methods convey requirements for precision
among each other?&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;To which degree should numerical methods be inspired by existing numerical
frameworks, and where should we deviate from established concepts? Is there a
place for ab initio probabilistic solutions to existing numerical problems?&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;In building probabilistic methods, when are richer models worth their
associated computational cost? Can we develop families of numerical methods
with cost/accuracy trade-offs tunable to the requirements of the problem at
hand?&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Can we support new probabilistic numerical methods with the theory required
for them to find broad acceptance?&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;forming-a-community&quot;&gt;Forming a community&lt;/h2&gt;

&lt;p&gt;Over the past years, a number of researchers stemming largely from the areas of
machine learning and statistics have attempted to build such probabilistic
numerical methods. A first meeting point for this group was the 2013 NIPS
Workshop on Probabilistic Numerics. Probabilistic Numerics is still a fledgling
community, in fact many of us do not know each other well, and we do not always
know of each other’s work. The Probabilistic Numerics Roundtable hopes to
alleviate this problem.&lt;/p&gt;

</description>
				<pubDate>Fri, 22 Aug 2014 11:00:00 +0200</pubDate>
				<link>http://www.probabilistic-numerics.org/test/2014/08/22/Roundtable-2014-in-Tuebingen</link>
				<guid isPermaLink="true">http://www.probabilistic-numerics.org/test/2014/08/22/Roundtable-2014-in-Tuebingen</guid>
			</item>
		
	</channel>
</rss>
