---
layout:     post
title:      "Connections, Part I: Uncertainty Quantification"
date:       2015-01-01 06:00:00
published:  true
comments:   true
author:     phennig
categories: general
---

*As I go around presenting the idea of probabilistic numerics to various
 audiences, certain questions about related areas come up repeatedly. This post
 explains how probabilistic numerics compares to the established area of
 Uncertainty Quantification. Subsequent posts will discuss connections to
 certain kinds of [stochastic numerical methods]({% post_url 2015-01-02-Stochastics %}), and the young and popular area
 of [Bayesian Optimization]({% post_url 2015-01-03-BO %}).*

*A disclaimer: Obviously, everyone has different opinions about the scope and
 purpose of certain concepts and academic fields. And I am not an expert in the
 areas discussed here. This post relates a part of my own personal
 justification, why I think certain ideas are novel and interesting. It is not
 intended as a holistic overview of a field. If anyone disagrees with
 characterizations I make here, I would be glad if you could relate your
 opinion in the comments section below.*

**Uncertainty Quantification (UQ)** is a relatively young area (but
considerably older than probabilistic numerics) at the boundary of numerical
mathematics and statistics, dealing with 'ill-posed' or 'inverse' problems. Or,
as [SIAM and the ASA](http://www.siam.org/journals/juq.php) define it: *"the
interface of complex modeling of processes and data, especially
characterizations of the uncertainties inherent in the use of such models."*
Although the academic communities are almost disconnected, conceptually, UQ is
closely linked to Bayesian machine learning and Bayesian statistics (but UQ has
a focus on partial and stochastic differential equations, dynamical systems,
which are still largely ignored by machine learning). Although UQ makes heavy
use of numerical methods, uncertainty created by their computation itself is
not usually an aspect of interest. In contrast, with probabilistic numerics we
put the computation itself in the center and ask about uncertainty created by
performing computations approximately. This applies even, and particularly, to
well-posed, deterministic problems.

### an example ###

Here is a pared-down, elementary illustration to highlight differences between
 the two aspects: Consider the linear problem of finding $$x\in\mathbb{R}^N$$
 such that $$Ax=b$$ with $$b\in\mathbb{R}^M$$ and a matrix
 $$A\in\mathbb{R}^{M\times N}$$. If $$M<N$$, there are generally many $$x$$
 that solve the problem. Identifying the space $$\{x\in\mathbb{R}^N\mid
 Ax=b\}$$ is an uncertainty quantification task (a trivial one, solved by a
 straightforward singular value decomposition. Research in UQ deals with much
 more challenging problems, of course).

Now let's assume $$N=M$$ and $$A$$ is nonsingular, so that there is only one
 unique $$x$$ satisfying $$Ax=b$$. Then the problem is 'well-posed', and from
 an analytic perspective, there is no uncertainty to be quantified. But there
 can still be computational uncertainty: If $$N$$ is too large for an exact
 solution (e.g. by Gauss-Jordan elimination) we would use an iterative
 method. For example, if $$A$$ happens to also be symmetric positive definite,
 the
 [method of conjugate gradients (CG)](http://en.wikipedia.org/wiki/Conjugate_gradient_method)
 would be a standard approach. CG is an iterative algorithm producing a
 sequence of increasingly better *approximations* $$\{x_i\}_{i=1,\dots,N}$$ to
 the correct $$x$$. The quality of this approximation as such can be assessed
 by the residual $$r_i = Ax_i-b$$, but there are questions for which the
 residual alone is not sufficient: Maybe we also need to solve the related
 problem $$Ay=c$$. How much do we learn about $$y$$ from computing $$x_i$$?
 This is the kind of problem answered by probabilistic numerics (shameless
 plug: the precise answer to this particular problem can be found in a recent
 paper by myself, currently in press {% cite 2014arXiv14022058H --file LinearAlgebra %}).

So, simplifying a bit: UQ concerns the space of all feasible solutions assuming
precise computations. Probabilistic numerics then concerns the computations
used to find this space: what is the uncertainty added by performing the
computation approximately? PN and UQ can live very well next to each other. PN
can learn much from UQ, in particular in areas like uncertainty propagation,
which is an established concept in UQ. Conversely, I hope colleagues working in
UQ will be interested in how our results on PN can help in large scale UQ. The
existence of UQ as such is no reason not to study PN.

### References

{% bibliography --cited --file LinearAlgebra %}

