@article{o1991bayes,
  title =	 {{B}ayes--{H}ermite quadrature},
  author =	 {O'Hagan, A.},
  journal =	 {Journal of statistical planning and inference},
  volume =	 29,
  number =	 3,
  pages =	 {245--260},
  year =	 1991,
  abstract =	 {Bayesian quadrature treats the problem of numerical
                  integration as one of statistical inference. A prior Gaussian
                  process distribution is assumed for the integrand,
                  observations arise from evaluating the integrand at selected
                  points, and a posterior distribution is derived for the
                  integrand and the integral. Methods are developed for
                  quadrature in p. A particular application is integrating the
                  posterior density arising from some other Bayesian analysis.
                  Simulation results are presented, to show that the resulting
                  Bayes–Hermite quadrature rules may perform better than the
                  conventional Gauss–Hermite rules for this application. A key
                  result is derived for product designs, which makes Bayesian
                  quadrature practically useful for integrating in several
                  dimensions. Although the method does not at present provide a
                  solution to the more difficult problem of quadrature in high
                  dimensions, it does seem to offer real improvements over
                  existing methods in relatively low dimensions.}
}

@techreport{minka2000deriving,
  author =	 {T.P. Minka},
  institution =	 {Statistics Department, Carnegie Mellon University},
  title =	 {{Deriving quadrature rules from {G}aussian processes}},
  year =	 2000,
  link = {http://research.microsoft.com/en-us/um/people/minka/papers/quadrature.html},
  abstract =	 {Quadrature rules are often designed to achieve zero error on
                  a small set of functions, e.g. polynomials of specified
                  degree. A more robust method is to minimize average error
                  over a large class or distribution of functions. If functions
                  are distributed according to a Gaussian process, then
                  designing an average-case quadrature rule reduces to solving
                  a system of 2n equations, where n is the number of nodes in
                  the rule (O'Hagan, 1991). It is shown how this very general
                  technique can be used to design customized quadrature rules,
                  in the style of Yarvin & Rokhlin (1998), without the need for
                  singular value decomposition and in any number of
                  dimensions. It is also shown how classical Gaussian
                  quadrature rules, trigonometric lattice rules, and spline
                  rules can be extended to the average-case and to multiple
                  dimensions by deriving them from Gaussian processes. In
                  addition to being more robust, multidimensional quadrature
                  rules designed for the average-case are found to be much less
                  ambiguous than those designed for a given polynomial degree.}
}

@inproceedings{ghahramani2002bayesian,
  title={Bayesian {Monte Carlo}},
  author={Ghahramani, Zoubin and Rasmussen, Carl E},
  booktitle={Advances in neural information processing systems},
  pages={489--496},
  link={http://machinelearning.wustl.edu/mlpapers/paper_files/AA01.pdf},
  year={2002},
  abstract = { We investigate Bayesian alternatives to classical Monte Carlo
    methods for evaluating integrals. Bayesian Monte Carlo (BMC) allows the in-
    corporation of prior knowledge, such as smoothness of the integrand, into
    the estimation. In a simple problem we show that this outperforms any
    classical importance sampling method. We also attempt more chal- lenging
    multidimensional integrals involved in computing marginal like- lihoods of
    statistical models (a.k.a. partition functions and model evi- dences). We
    find that Bayesian Monte Carlo outperformed Annealed Importance Sampling,
    although for very high dimensional problems or problems with massive
    multimodality BMC may be less adequate. One advantage of the Bayesian
    approach to Monte Carlo is that samples can be drawn from any distribution.
    This allows for the possibility of active design of sample points so as to
    maximise information gain. }
}


@inproceedings{osborne2012bayesian,
  author =	 {M.A. Osborne and R. Garnett and S.J. Roberts and C. Hart and
                  S.  Aigrain and N. Gibson},
  booktitle =	 {{International Conference on Artificial Intelligence and
                  Statistics}},
  pages =	 {832--840},
  title =	 {{Bayesian quadrature for ratios}},
  year =	 2012,
  abstract =	 {We describe a novel approach to quadrature for ratios of
                  probabilistic integrals, such as are used to compute
                  posterior probabilities. This approach offers performance
                  superior to Monte Carlo methods by exploiting a Bayesian
                  quadrature framework. We improve upon previous Bayesian
                  quadrature techniques by explicitly modelling the
                  non-negativity of our integrands, and the correlations that
                  exist between them. It offers most where the integrand is
                  multi-modal and expensive to evaluate. We demonstrate the
                  efficacy of our method on data from the Kepler space
                  telescope.},
  file =	 {../assets/pdf/Osborne2012Bayesian.pdf}
}


@inproceedings{osborne2012active,
  author =	 {M.A. Osborne and D.K. Duvenaud and R. Garnett and
                  C.E. Rasmussen and S.J. Roberts and Z. Ghahramani},
  booktitle =	 {{Advances in Neural Information Processing Systems (NIPS)}},
  pages =	 {46--54},
  title =	 {{Active Learning of Model Evidence Using Bayesian
                  Quadrature.}},
  year =	 2012,
  abstract =	 { Numerical integration is a key component of many problems in
                  scientific computing, statistical modelling, and machine
                  learning. Bayesian Quadrature is a model-based method for
                  numerical integration which, relative to standard Monte Carlo
                  methods, offers increased sample efficiency and a more robust
                  estimate of the uncertainty in the estimated integral. We
                  propose a novel Bayesian Quadrature approach for numerical
                  integration when the integrand is non-negative, such as the
                  case of computing the marginal likelihood, predictive
                  distribution, or normalising constant of a probabilistic
                  model. Our approach approximately marginalises the quadrature
                  model’s hyperparameters in closed form, and introduces an ac-
                  tive learning scheme to optimally select function
                  evaluations, as opposed to using Monte Carlo samples. We
                  demonstrate our method on both a number of synthetic
                  benchmarks and a real scientific problem from astronomy.},
 file =	 {../assets/pdf/Osborne2012active.pdf
}
}

